{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn import metrics, linear_model\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1 Load files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/ryanhuang/Desktop/107-2/statistical learning/Assignments/Assign3/phone_train.pickle', 'rb') as fh1:\n",
    "    traindata = pickle.load(fh1)\n",
    "\n",
    "with open('/Users/ryanhuang/Desktop/107-2/statistical learning/Assignments/Assign3/phone_test1.pickle', 'rb') as fh2:\n",
    "    test = pickle.load(fh2)\n",
    "\n",
    "x_train = traindata.iloc[:,0:3]\n",
    "y_train = traindata.iloc[:,3]\n",
    "\n",
    "x_test = test.iloc[:,0:3]\n",
    "y_test = test.iloc[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Self-defined generative classification class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mypgc:\n",
    "    def fit(self, X_train, Y_train):\n",
    "        def model_info(x_train,y_train, ylab):\n",
    "            info_collection = dict()\n",
    "            for lab in ylab:\n",
    "                info = dict()\n",
    "                data = x_train.loc[y_train == lab,]\n",
    "                info['mu'] = data.mean(0)\n",
    "                info['cov'] = data.cov(0)\n",
    "                info['prec'] = np.linalg.inv(data.cov(0))\n",
    "                info['detcov'] = np.linalg.det(data.cov(0))\n",
    "                info['n'] = data.shape[0]\n",
    "                info['prior'] = data.shape[0] / x_train.shape[0]\n",
    "                info_collection[lab] = info\n",
    "            return info_collection\n",
    "        self.xtrain = X_train\n",
    "        self.ytrain = Y_train\n",
    "        self.ylab = self.ytrain.unique()\n",
    "        self.model = model_info(self.xtrain,self.ytrain, self.ylab)\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        prediction = []\n",
    "        for i in range(x_test.shape[0]):\n",
    "            p_list = []\n",
    "            for lab in self.ylab:\n",
    "                p_list.append(((2 * np.pi) ** (-3 / 2)) \\\n",
    "                              * (self.model[lab][\"detcov\"] ** (-1 / 2)) \\\n",
    "                              * np.exp(\n",
    "                                        (-0.5) * (x_test.iloc[i,:] - self.model[lab][\"mu\"]).T \\\n",
    "                                        .dot(self.model[lab][\"prec\"]) \\\n",
    "                                        .dot(x_test.iloc[i,:] - self.model[lab][\"mu\"])) \\\n",
    "                              * self.model[lab][\"prior\"])\n",
    "            prediction.append(self.ylab[np.asarray(p_list).argmax()])\n",
    "        return np.asarray(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Phoneonback': {'mu': x    0.206933\n",
      "y   -0.026152\n",
      "z    9.796376\n",
      "dtype: float64, 'cov':           x         y         z\n",
      "x  0.002990 -0.001958  0.002848\n",
      "y -0.001958  0.002299 -0.002425\n",
      "z  0.002848 -0.002425  0.004888, 'prec': array([[ 943.63669582,  469.54782044, -316.78479596],\n",
      "       [ 469.54782044, 1146.63145078,  295.42598486],\n",
      "       [-316.78479596,  295.42598486,  535.76812508]]), 'detcov': 5.673178805678628e-09, 'n': 28566, 'prior': 0.17095459523510295}, 'Phoneonbottom': {'mu': x    0.190768\n",
      "y    9.785847\n",
      "z    0.146557\n",
      "dtype: float64, 'cov':           x         y         z\n",
      "x  0.002739 -0.004438  0.001520\n",
      "y -0.004438  0.010268 -0.003281\n",
      "z  0.001520 -0.003281  0.002480, 'prec': array([[1229.24902343,  503.42022589,  -87.22678994],\n",
      "       [ 503.42022589,  374.93550309,  187.61601574],\n",
      "       [ -87.22678994,  187.61601574,  705.02302834]]), 'detcov': 1.1952712798255282e-08, 'n': 27842, 'prior': 0.1666217825574367}, 'Phoneonfront': {'mu': x    0.112704\n",
      "y    0.142651\n",
      "z   -9.735796\n",
      "dtype: float64, 'cov':           x         y         z\n",
      "x  0.001736 -0.005622  0.000713\n",
      "y -0.005622  0.030700 -0.003862\n",
      "z  0.000713 -0.003862  0.001856, 'prec': array([[1415.5956848 ,  258.4845593 ,   -6.15206605],\n",
      "       [ 258.4845593 ,   91.32078358,   90.68682325],\n",
      "       [  -6.15206605,   90.68682325,  729.91124637]]), 'detcov': 2.9712670166559285e-08, 'n': 29079, 'prior': 0.1740246683064328}, 'Phoneonleft': {'mu': x    9.926394\n",
      "y    0.092757\n",
      "z   -0.019335\n",
      "dtype: float64, 'cov':           x         y         z\n",
      "x  0.001928 -0.006193  0.000636\n",
      "y -0.006193  0.032008 -0.003176\n",
      "z  0.000636 -0.003176  0.001720, 'prec': array([[1369.95113577,  263.0134811 ,  -20.49603676],\n",
      "       [ 263.0134811 ,   88.74589895,   66.6992188 ],\n",
      "       [ -20.49603676,   66.6992188 ,  712.14869845]]), 'detcov': 3.282281658720189e-08, 'n': 29522, 'prior': 0.17667582302494958}, 'Phoneonright': {'mu': x   -9.649160\n",
      "y    0.078687\n",
      "z   -0.007718\n",
      "dtype: float64, 'cov':           x         y         z\n",
      "x  0.000767 -0.000671  0.000687\n",
      "y -0.000671  0.006824 -0.006271\n",
      "z  0.000687 -0.006271  0.007733, 'prec': array([[1432.0246564 ,   93.75083518,  -51.14931824],\n",
      "       [  93.75083518,  581.24293978,  463.03773646],\n",
      "       [ -51.14931824,  463.03773646,  509.36831176]]), 'detcov': 9.389257143958892e-09, 'n': 25687, 'prior': 0.1537250818386925}, 'Phoneontop': {'mu': x    0.000814\n",
      "y   -9.699908\n",
      "z   -0.100216\n",
      "dtype: float64, 'cov':           x         y         z\n",
      "x  0.001847  0.005293 -0.006014\n",
      "y  0.005293  0.025195 -0.027921\n",
      "z -0.006014 -0.027921  0.033118, 'prec': array([[1380.20106989, -186.01874711,   93.79832935],\n",
      "       [-186.01874711,  629.12383998,  496.62195539],\n",
      "       [  93.79832935,  496.62195539,  465.9185559 ]]), 'detcov': 3.9723671816650924e-08, 'n': 26401, 'prior': 0.15799804903738546}}\n"
     ]
    }
   ],
   "source": [
    "pgc1 = mypgc()\n",
    "pgc1.fit(x_train, y_train)\n",
    "pred = pgc1.predict(x_test.iloc[0:20,])\n",
    "print(pgc1.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test.iloc[0:20,], pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_2.1 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data, N/A values are '?'\n",
    "header_list = ['age','workclass','fnlwgt','education','education-num','marital-status','occupation',\n",
    "               'relationship','race','sex','capital-gain','capital-loss','hours-per-week','native-country', 'attribute']\n",
    "q2_train_path = '/Users/ryanhuang/Desktop/107-2/statistical learning/Assignments/Assign3/adult.data.txt'\n",
    "q2_train_raw = pd.read_csv(q2_train_path, header = None, names = header_list, na_values=['?'], skipinitialspace=True)\n",
    "q2_test_path = '/Users/ryanhuang/Desktop/107-2/statistical learning/Assignments/Assign3/adult.test.txt'\n",
    "q2_test_raw = pd.read_csv(q2_test_path, header = None, names = header_list, na_values=['?'], skipinitialspace=True)\n",
    "q2_train_raw.dropna(axis=0, inplace=True)\n",
    "q2_test_raw.dropna(axis=0, inplace=True)\n",
    "q2_test_raw['age'] = q2_test_raw['age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the category variables with 1 hot encoding\n",
    "class_var_list = ['workclass', 'education', 'marital-status','occupation','relationship','race','native-country','sex']\n",
    "class_others = []\n",
    "small_class_col = []\n",
    "for col in class_var_list:\n",
    "    other_value = q2_train_raw[col].value_counts()\\\n",
    "                         .index\\\n",
    "                         [q2_train_raw[col].value_counts()<10]\n",
    "    if len(other_value) > 0:\n",
    "        class_others.append(other_value[:len(other_value)])\n",
    "        small_class_col.append(col)\n",
    "for col in small_class_col:\n",
    "    q2_train_raw.loc[:,col] = q2_train_raw.loc[:,col].apply(lambda x: 'others' if x in class_others else x)\n",
    "    q2_test_raw.loc[:,col] = q2_test_raw.loc[:,col].apply(lambda x: 'others' if x in class_others else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exec-managerial      1992\n",
       "Craft-repair         1990\n",
       "Prof-specialty       1970\n",
       "Sales                1824\n",
       "Adm-clerical         1819\n",
       "Other-service        1596\n",
       "Machine-op-inspct    1004\n",
       "Transport-moving      744\n",
       "Handlers-cleaners     696\n",
       "Tech-support          508\n",
       "Farming-fishing       491\n",
       "Protective-serv       332\n",
       "Priv-house-serv        89\n",
       "others                  5\n",
       "Name: occupation, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-hot encoding for class_vars\n",
    "# The conti. vars are from column_1 to column_7, column_8 is the attribute\n",
    "q2_train = pd.get_dummies(q2_train_raw)\n",
    "q2_test  = pd.get_dummies(q2_test_raw)\n",
    "q2_train_raw['occupation'].value_counts()\n",
    "q2_test_raw['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['attribute_>50K', 'native-country_others', 'attribute_<=50K']\n",
      "['attribute_>50K.', 'attribute_<=50K.']\n"
     ]
    }
   ],
   "source": [
    "# check different columns in test and training\n",
    "train_col = q2_train.columns.tolist()\n",
    "test_col = q2_test.columns.tolist()\n",
    "print(list(set(train_col).difference(set(test_col)))) # in train not in test\n",
    "print(list(set(test_col).difference(set(train_col)))) # in test not in train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add native-country_others to testing data\n",
    "q2_test['native-country_others'] = 0\n",
    "\n",
    "# rename columns\n",
    "q2_test = q2_test.rename({'attribute_<=50K.':'attribute_<=50K','attribute_>50K.':'attribute_>50K'}, axis='columns')\n",
    "\n",
    "# Rearrange the col order\n",
    "q2_test = q2_test[q2_train.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    15060.000000\n",
       "mean         0.245684\n",
       "std          0.430506\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          0.000000\n",
       "75%          0.000000\n",
       "max          1.000000\n",
       "Name: attribute_>50K, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seperate train_x, train_y, test_x, test_y\n",
    "x_train, y_train = np.asarray(q2_train.iloc[:,:-2]), np.asarray(q2_train.iloc[:,-1])\n",
    "x_test, y_test   = np.asarray(q2_test.iloc[:,:-2]), np.asarray(q2_test.iloc[:,-1])\n",
    "\n",
    "# x_train\n",
    "q2_train.iloc[:,:-2].describe()\n",
    "# y_train\n",
    "q2_train.iloc[:,-1].describe()\n",
    "# x_test\n",
    "q2_test.iloc[:,:-2].describe()\n",
    "# y_test\n",
    "q2_test.iloc[:,-1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_2.2: Derive the gradient and hession matrix for the new E(w).\n",
    "# Gradient = Λw + ∑(yn - tn)xn\n",
    "# Hession = Λ + x^T * R * x, where R is NxN diagonal matrix with the diagonal is yn * ( 1-yn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_2.3: Self-define Logistics Regresser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mylogistic_l2:\n",
    "    def __init__(self, reg_vec, max_iter, tol, add_intercept = True):\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "\n",
    "    def __sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        if self.add_intercept:\n",
    "            self.x_train = np.c_[ x_train, np.ones(x_train.shape[0]) ]\n",
    "        else:\n",
    "            self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "\n",
    "        # initial w vector given by ridge regression\n",
    "        w = np.linalg.inv( self.x_train.T.dot(self.x_train) +\n",
    "                                (np.diag(self.reg_vec).mean()\n",
    "                                    * np.identity(self.x_train.shape[1]))) \\\n",
    "                .dot(self.x_train.T) \\\n",
    "                .dot(self.y_train)\n",
    "\n",
    "        # IRLS Loop to find optimal w\n",
    "        error = []\n",
    "        best_w = None\n",
    "        for i in range(self.max_iter):\n",
    "            y = self.__sigmoid(np.dot(self.x_train, w)) # y = n(data size) * 1, each element is in [0,1]\n",
    "            # y = 1 / (1 + np.exp((-self.w).T.dot(self.x_train.T)))\n",
    "            t = self.y_train  # t = n(data size) * 1\n",
    "            gradient = self.reg_vec.dot(w) + self.x_train.T.dot(y - t)  # gradient = m(feature size) * 1\n",
    "            R = np.diagflat(y * (1 - y))\n",
    "            hession = self.reg_vec + self.x_train.T.dot(R).dot(self.x_train)\n",
    "            w = w - np.linalg.inv(hession).dot(gradient)\n",
    "            new_error = 0.5 * w.T.dot(self.reg_vec).dot(w) - (t * np.log(y) + (1 - t * np.log((1 - y)))).sum()\n",
    "            if i > 0 and new_error < error[-1]:\n",
    "                best_w = w\n",
    "            if i > 0 and abs(new_error - error[-1]) <= self.tol:\n",
    "                break\n",
    "            else:\n",
    "                error.append(new_error)\n",
    "\n",
    "            # w is determined after the IRLS converged\n",
    "            self.w = best_w\n",
    "        self.error_list = error\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        if self.add_intercept:\n",
    "            self.x_test = np.c_[x_test, np.ones(x_test.shape[0])]\n",
    "        else:\n",
    "            self.x_test = x_test\n",
    "        pred = self.__sigmoid(np.dot(self.x_test, self.w))\n",
    "        return pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.84800796812749\n"
     ]
    }
   ],
   "source": [
    "# case_1: lambda = 1 for all coefficients\n",
    "lambda_vec_1 = np.diagflat([1] * (x_train.shape[1]+1))\n",
    "logic1 = mylogistic_l2(reg_vec = lambda_vec_1, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic1.fit(x_train, y_train)\n",
    "ypred1 = logic1.predict(x_test)\n",
    "print('accuracy is', metrics.accuracy_score(y_test, ypred1))\n",
    "#print('coefficients w are', logic1.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    obj_function value= [-34112.21628423518, -31313.63812950806, -33976.702408429876, -37169.1168387285, -38992.06826924892, -39368.33721684105, -39382.786108549466, -39382.80024352845]\n",
      "    w[0:5] (numerical-valued coef) =  [2.48542874e-02 7.26628938e-07 1.86052927e-01 3.16575978e-04\n",
      " 6.38741410e-04]\n",
      "    w[10:15] (binary-valued coef) =  [-0.7932101  -0.61782768 -1.17218718 -0.45123745 -0.54415846]\n",
      "    w[-1] (incercept) =  -3.32567134748659\n"
     ]
    }
   ],
   "source": [
    "#print(\"    num of iteration =\", logic1.niter)\n",
    "print(\"    obj_function value=\", logic1.error_list)\n",
    "print(\"    w[0:5] (numerical-valued coef) = \", logic1.w[0:5])\n",
    "print(\"    w[10:15] (binary-valued coef) = \", logic1.w[10:15])\n",
    "print(\"    w[-1] (incercept) = \", logic1.w[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.847875166002656\n",
      "coefficients w are [ 2.54295548e-02  7.50945179e-07  2.95317307e-01  3.17014683e-04\n",
      "  6.39715093e-04  2.94903835e-02  7.06908026e-01  1.75726588e-02\n",
      "  2.08885351e-01  3.82528927e-01 -2.80056412e-01 -1.04778523e-01\n",
      " -9.31060027e-01  9.06214969e-02 -1.06411979e-01 -5.47663220e-02\n",
      "  7.05949201e-01  5.35843404e-01  1.16205771e-01  1.37324858e-01\n",
      " -4.02159115e-01 -1.13538481e-01 -7.45191900e-02  6.78820737e-02\n",
      " -1.97258204e-02 -1.15573834e-02 -1.15970847e+00  2.66928077e-01\n",
      "  2.16318781e-02 -5.26718255e-01  1.61472912e+00  1.36800663e+00\n",
      " -4.92649813e-01 -1.01532182e+00 -6.05953641e-01 -3.42092226e-01\n",
      "  1.49997638e-01  2.14446830e-01  9.50862583e-01 -8.31719218e-01\n",
      " -5.34580247e-01 -1.13006170e-01 -6.63135450e-01 -1.56103460e+00\n",
      "  6.64398431e-01  7.37162512e-01  4.41486031e-01  8.04743727e-01\n",
      "  5.92587204e-02 -3.18880788e-01 -4.27131102e-02  1.99548659e-01\n",
      " -5.82604954e-01 -9.37093672e-01  7.54141887e-02  1.28744889e+00\n",
      " -3.71026282e-01  3.94087782e-01  4.28275455e-02 -2.61547780e-01\n",
      "  1.95658735e-01 -4.27232538e-01  4.27232538e-01  1.00935987e+00\n",
      "  5.02405437e-01 -4.58314312e-01 -1.24063322e+00  5.27808969e-01\n",
      " -8.67755885e-01 -2.76235304e-02 -3.15465085e-01  4.72848957e-01\n",
      "  6.28731874e-01  6.23937266e-01 -5.88350316e-01 -2.98148906e-02\n",
      "  1.24871586e-01 -1.43559796e-01  2.48614746e-02  6.16051772e-02\n",
      " -2.48744936e-01  1.94804698e-01  5.25969649e-01  9.31996289e-01\n",
      "  1.87646721e-01  3.79682860e-01 -2.87274504e-01 -3.10495389e-01\n",
      " -3.32728481e-01 -6.50738059e-01 -3.81248647e-01  4.88998893e-01\n",
      "  1.76325239e-01  1.74438505e-01 -7.36715468e-02 -3.10711593e-02\n",
      " -8.98397396e-01  6.82847520e-03 -2.72088878e-01 -1.23806736e-01\n",
      "  3.96863071e-01 -7.54301745e-01  6.10571936e-01 -1.44724400e-02\n",
      " -8.87251278e+00]\n"
     ]
    }
   ],
   "source": [
    "#case_2: lambda = 1 for all but the intercept, no regularization for intercept term.\n",
    "lambda_vec_2 = np.diagflat([1] * x_train.shape[1] + [0])\n",
    "logic2 = mylogistic_l2(reg_vec = lambda_vec_2, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic2.fit(x_train, y_train)\n",
    "ypred2 = logic2.predict(x_test)\n",
    "print('accuracy is', metrics.accuracy_score(y_test, ypred2))\n",
    "print('coefficients w are', logic2.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.847675962815405\n",
      "coefficients w are [ 2.54695730e-02  7.52271368e-07  3.19083151e-01  3.17302273e-04\n",
      "  6.40217484e-04  2.95117222e-02  6.64828492e-01 -2.52083943e-02\n",
      "  1.66636693e-01  3.41825852e-01 -3.22314402e-01 -1.47691017e-01\n",
      " -1.34290572e+00  2.18750528e-01 -2.51809332e-03  2.46020712e-02\n",
      "  9.74746677e-01  7.53811068e-01  2.92003188e-01  2.92813679e-01\n",
      " -4.19830245e-01 -1.04556378e-01 -1.13126008e-01 -3.79911613e-02\n",
      "  3.74637445e-02 -7.29987343e-02 -2.08397342e+00  1.86159291e-01\n",
      "  5.46437935e-02 -5.72264656e-01  1.82621717e+00  1.39690722e+00\n",
      " -5.47321824e-01 -1.05939403e+00 -6.55939889e-01 -3.88203989e-01\n",
      "  2.00468981e-01  2.64389652e-01  1.00237908e+00 -7.88410386e-01\n",
      " -4.89003477e-01 -6.26537026e-02 -6.18079609e-01 -2.02574798e+00\n",
      "  7.15127317e-01  7.91547668e-01  4.92474266e-01  8.59371725e-01\n",
      "  1.09407405e-01 -4.51270945e-01 -8.41153035e-02  2.32836754e-01\n",
      " -5.91522369e-01 -9.22950452e-01  1.11386339e-01  1.25436503e+00\n",
      " -3.82279092e-01  4.12693607e-01  4.11262166e-02 -2.64306396e-01\n",
      "  1.92765664e-01 -4.29212201e-01  4.29212201e-01  1.18883684e+00\n",
      "  5.50861044e-01 -4.76689373e-01 -1.45904240e+00  5.82211038e-01\n",
      " -1.06222863e+00 -9.48344904e-03 -3.18407756e-01  5.24273456e-01\n",
      "  7.29271027e-01  6.74497477e-01 -6.38163130e-01 -9.81986225e-03\n",
      "  1.74149106e-01 -2.36223947e-01  3.80603758e-02  1.00471448e-01\n",
      " -2.47272553e-01  2.38245021e-01  6.41997725e-01  1.00608396e+00\n",
      "  2.33027040e-01  4.22895438e-01 -3.52967031e-01 -2.90871872e-01\n",
      " -3.81024934e-01 -9.62386061e-01 -4.49668201e-01  5.13082436e-01\n",
      "  2.19889579e-01  2.26923215e-01 -5.00080950e-02 -1.78871596e-02\n",
      " -9.59592675e-01  1.67192841e-02 -3.27244221e-01 -1.39522054e-01\n",
      "  4.28468718e-01 -8.46071998e-01  7.51140757e-01 -2.65295845e-02\n",
      " -9.17300378e+00]\n"
     ]
    }
   ],
   "source": [
    "#case_3: lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for incercept\n",
    "lambda_vec_3 = np.diagflat([1] * 7 + [0.5] *(x_train.shape[1]-7) + [0])\n",
    "logic3 = mylogistic_l2(reg_vec = lambda_vec_3, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic3.fit(x_train, y_train)\n",
    "ypred3 = logic3.predict(x_test)\n",
    "metrics.accuracy_score(y_test, ypred3)\n",
    "print('accuracy is', metrics.accuracy_score(y_test, ypred3))\n",
    "print('coefficients w are', logic3.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q_2.4: Parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanhuang/.conda/envs/untitled/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "def lambda_vec(a1, a2):\n",
    "    return np.diagflat([a1] * 7 + [a2] * 97 + [0])\n",
    "\n",
    "x_subtrain, x_tuning, y_subtrain, y_tuning = train_test_split(x_train,y_train, train_size=0.9)\n",
    "lambda_list = np.logspace(-2,2,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1, a2 are 1.6681005372000592\n"
     ]
    }
   ],
   "source": [
    "# stage_1\n",
    "stage_1 = []\n",
    "for i in lambda_list:\n",
    "    q2_4_logic = mylogistic_l2(max_iter = 1000, tol = 1e-5, add_intercept = True, reg_vec=lambda_vec(i,i))\n",
    "    q2_4_logic.fit(x_subtrain, y_subtrain)\n",
    "    ypred = q2_4_logic.predict(x_tuning)\n",
    "    stage_1.append(metrics.accuracy_score(y_tuning, ypred))\n",
    "\n",
    "print('a1, a2 are', lambda_list[stage_1.index(max(stage_1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new a2 is 4.6415888336127775\n"
     ]
    }
   ],
   "source": [
    "# stage 2: fixed a1\n",
    "\n",
    "stage_2 = []\n",
    "for i in lambda_list:\n",
    "    q2_4_logic = mylogistic_l2(max_iter = 1000, tol = 1e-5, add_intercept = True, reg_vec=lambda_vec(lambda_list[stage_1.index(max(stage_1))],i))\n",
    "    q2_4_logic.fit(x_subtrain, y_subtrain)\n",
    "    ypred = q2_4_logic.predict(x_tuning)\n",
    "    stage_2.append(metrics.accuracy_score(y_tuning, ypred))\n",
    "print('new a2 is', lambda_list[stage_2.index(max(stage_2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new a1 is 0.01\n"
     ]
    }
   ],
   "source": [
    "# stage 3: fixed a2\n",
    "stage_3 = []\n",
    "for i in lambda_list:\n",
    "    q2_4_logic = mylogistic_l2(max_iter = 1000, tol = 1e-5, add_intercept = True, reg_vec=lambda_vec(i,lambda_list[stage_2.index(max(stage_2))]))\n",
    "    q2_4_logic.fit(x_subtrain, y_subtrain)\n",
    "    ypred = q2_4_logic.predict(x_tuning)\n",
    "    stage_3.append(metrics.accuracy_score(y_tuning, ypred))\n",
    "print('new a1 is', lambda_list[stage_3.index(max(stage_3))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best pair of (a1, a2) is ( 0.01 , 4.6415888336127775 )\n",
      "The resulting accuracy is 0.84867197875166\n"
     ]
    }
   ],
   "source": [
    "# Final summary\n",
    "q2_4_logic_final = mylogistic_l2(max_iter = 1000, tol = 1e-5, add_intercept = True, reg_vec=lambda_vec(lambda_list[stage_3.index(max(stage_3))],lambda_list[stage_2.index(max(stage_2))]))\n",
    "q2_4_logic_final.fit(x_train, y_train)\n",
    "q2_5_logic_final_pred = q2_4_logic_final.predict(x_test)\n",
    "print('The best pair of (a1, a2) is (',lambda_list[stage_3.index(max(stage_3))],',',lambda_list[stage_2.index(max(stage_2))],')')\n",
    "print('The resulting accuracy is', metrics.accuracy_score(y_test, q2_5_logic_final_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best pair of (a1, a2) is ( 0.01 , 4.6415888336127775 )\n"
     ]
    }
   ],
   "source": [
    "print('The best pair of (a1, a2) is (',lambda_list[stage_3.index(max(stage_3))],',',lambda_list[stage_2.index(max(stage_2))],')')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanhuang/.conda/envs/untitled/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 0.01, 'penalty': 'l2'}\n",
      "accuracy : 0.7906428439860012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ryanhuang/.conda/envs/untitled/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Q_2.5: Compare with standard logistics regression in sklearn library\n",
    "grid={\"C\":np.logspace(-2,2,10),\"penalty\":[\"l2\"]}\n",
    "q2_5_logic = linear_model.LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "logreg_cv=GridSearchCV(q2_5_logic,grid)\n",
    "logreg_cv.fit(x_subtrain,y_subtrain)\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)\n",
    "q2_5_logic_final = linear_model.LogisticRegression(C=logreg_cv.best_params_['C'], penalty='l2')\n",
    "q2_5_logic_final.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard logistc: [[-4.43024900e-03 -4.44696056e-06 -1.07673189e-03  3.29268998e-04\n",
      "   7.23501864e-04 -5.30129838e-03  1.11704532e-05 -2.71400492e-06\n",
      "  -2.62358318e-04  3.01794247e-05 -1.68307432e-05 -7.26456508e-06\n",
      "  -6.66149762e-07 -2.59136978e-05 -3.63494994e-05 -1.17330099e-05\n",
      "  -4.37246854e-06 -8.82781214e-06 -1.93126219e-05 -1.46962108e-05\n",
      "  -6.23255362e-06 -9.48487044e-06  7.71833849e-05  2.14917729e-05\n",
      "  -1.90942955e-04  5.24045572e-05 -1.75367020e-06  2.61823153e-05\n",
      "  -9.61265636e-05 -1.25696481e-04  6.53782706e-07  2.97104430e-04\n",
      "  -1.14511025e-05 -3.52568836e-04 -2.95307373e-05 -2.69949587e-05\n",
      "  -8.80763188e-05 -4.18075075e-05  9.19237969e-05 -3.12678338e-05\n",
      "  -4.34340521e-05 -4.63445175e-05 -1.18851681e-04 -5.80320458e-06\n",
      "   6.95120443e-05  4.97606820e-06 -1.86941032e-05  1.34495820e-06\n",
      "  -2.17704683e-05 -1.91083596e-07  2.65146064e-04 -2.28625709e-04\n",
      "  -3.12728230e-05 -1.80902915e-04 -1.09523799e-04  3.66952797e-05\n",
      "  -1.13932894e-05 -7.34624828e-06 -5.40734221e-05 -6.67688325e-06\n",
      "  -1.68994060e-04 -2.74276127e-04  2.57922238e-05  1.97798977e-07\n",
      "   2.84480773e-07 -1.73220985e-07 -1.84180981e-06  8.70888219e-07\n",
      "  -2.46841522e-06 -5.69617335e-07 -2.36578007e-06  4.87665664e-07\n",
      "   7.35760644e-07  8.21458931e-07 -6.35619194e-07 -1.63553671e-06\n",
      "  -9.41930672e-07 -2.60495629e-07  2.86729307e-07 -1.85715637e-07\n",
      "   8.73718550e-07  4.95200331e-07 -4.75580328e-07  6.68718575e-07\n",
      "  -1.48001623e-06  6.17997072e-07 -3.15216900e-07 -1.20255775e-05\n",
      "  -6.92377586e-07 -5.23373282e-07 -6.02527920e-07 -8.25899565e-08\n",
      "  -7.41219164e-07 -1.06509484e-06 -2.64068524e-06 -1.42003494e-07\n",
      "  -1.45015611e-06  1.05487948e-06 -1.96953900e-07 -5.10739649e-07\n",
      "  -2.19484615e-04 -2.57777546e-06  3.35045236e-07 -1.29600268e-07]]\n",
      "self-defined logistics: [ 2.54007685e-02  7.46897307e-07  2.79450423e-01  3.16012176e-04\n",
      "  6.37863270e-04  2.94452584e-02  7.36142009e-01  4.15822328e-02\n",
      "  2.28377602e-01  3.93367097e-01 -2.60673991e-01 -7.84834338e-02\n",
      " -3.25755478e-01  6.07459357e-03 -1.67157445e-01 -9.42441189e-02\n",
      "  3.36225550e-01  2.98853869e-01 -2.06597173e-03  2.27606568e-02\n",
      " -3.68998288e-01 -1.11648474e-01 -4.02775832e-02  1.29640625e-01\n",
      " -5.48561111e-02  3.33770263e-02 -2.98997239e-01  3.06284694e-01\n",
      "  5.02821598e-03 -3.72685160e-01  8.67162125e-01  1.29290635e+00\n",
      " -3.03605945e-01 -8.64309357e-01 -4.27508708e-01 -1.91959311e-01\n",
      "  5.46406976e-02  1.21369107e-01  8.49094197e-01 -8.78010900e-01\n",
      " -5.92761984e-01 -2.02130887e-01 -7.25312869e-01 -6.96978090e-01\n",
      "  5.65278022e-01  6.17144544e-01  3.43330429e-01  6.84663164e-01\n",
      " -3.18605943e-02 -1.08464838e-01  8.11874878e-02  8.79965403e-02\n",
      " -5.25641432e-01 -9.53898562e-01 -4.76503670e-02  1.35800633e+00\n",
      " -3.13747671e-01  3.06940588e-01  4.09673844e-02 -2.35565277e-01\n",
      "  2.01404975e-01 -4.12394707e-01  4.12394707e-01  4.93690770e-01\n",
      "  3.36246825e-01 -3.21150728e-01 -6.49813380e-01  3.38415742e-01\n",
      " -4.17121707e-01 -3.92694180e-02 -2.35218842e-01  3.00450188e-01\n",
      "  3.21673072e-01  4.42838419e-01 -3.59502004e-01 -4.04246424e-02\n",
      "  3.07522076e-02 -4.01264981e-02  1.42960906e-02  2.30684842e-03\n",
      " -1.96812800e-01  8.28369115e-02  2.21468336e-01  6.39049623e-01\n",
      "  7.42902693e-02  2.39387833e-01 -1.15425519e-01 -3.24978787e-01\n",
      " -1.75617478e-01 -2.16345328e-01 -1.85996764e-01  4.11561563e-01\n",
      "  6.37703058e-02  6.03412803e-02 -1.02321615e-01 -2.92259301e-02\n",
      " -5.91651363e-01  9.04201674e-03 -1.16533967e-01 -6.02475463e-02\n",
      "  3.09841902e-01 -4.22307476e-01  2.51978251e-01 -4.14666349e-03\n",
      " -8.56960018e+00]\n"
     ]
    }
   ],
   "source": [
    "# Compared with the standard model, our own model performances better with 5% higher accuracy score\n",
    "# However, when it comes to efficiency, the standard model is so much faster\n",
    "# Comparing the coefficients:\n",
    "print('standard logistc:', q2_5_logic_final.coef_)\n",
    "print('self-defined logistics:', q2_4_logic_final.w)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
